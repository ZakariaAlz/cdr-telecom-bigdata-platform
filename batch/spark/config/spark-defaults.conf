# ================================
# Spark Cluster Core Configuration
# ================================
spark.master                           spark://spark-master:7077
spark.driver.memory                    8g
spark.driver.maxResultSize             4g

# ================================
# Executor and Resource Tuning
# ================================
spark.executor.instances               2
spark.executor.cores                   6
spark.executor.memory                  8g
spark.executor.memoryOverhead          2g

# ================================
# Parallelism and Partitioning
# ================================
spark.default.parallelism              16
spark.sql.shuffle.partitions           24
spark.shuffle.compress           true
spark.shuffle.spill.compress     true
spark.sql.files.maxPartitionBytes      256m
spark.sql.adaptive.enabled             true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.advisoryPartitionSizeInBytes 64m
spark.sql.adaptive.skewJoin.enabled    true
spark.sql.adaptive.localShuffleReader.enabled true
spark.sql.adaptive.coalescePartitions.minPartitionSize 8m

# ================================
# IO, Compression, Serialization
# ================================
spark.sql.parquet.compression.codec    snappy
spark.io.compression.codec             lz4
spark.serializer                       org.apache.spark.serializer.KryoSerializer
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2

# ================================
# Hive & HDFS Integration
# ================================
spark.sql.catalogImplementation        hive
spark.hadoop.hive.metastore.uris       thrift://hive-metastore:9083
spark.sql.warehouse.dir                hdfs://namenode:9000/user/hive/warehouse
spark.hadoop.fs.defaultFS              hdfs://namenode:9000

# ================================
# Joins and Shuffle
# ================================
spark.sql.autoBroadcastJoinThreshold   20MB
spark.sql.broadcastTimeout             600
spark.sql.files.openCostInBytes        4MB

# ================================
# UI & Debug
# ================================
spark.ui.showConsoleProgress           true
spark.ui.retainedJobs                  50
spark.ui.retainedStages                50

# ================================
# Stability & Heartbeat
# ================================
spark.network.timeout                  120s
spark.executor.heartbeatInterval       10s
spark.rpc.message.maxSize              128

# ================================
# Memory Tuning
# ================================
spark.memory.fraction                  0.6
spark.memory.storageFraction           0.5

# ================================
# Safety
# ================================
spark.dynamicAllocation.enabled        false

# ================================
# Extra (Advanced, Optional)
# ================================
# spark.sql.execution.arrow.pyspark.enabled true

# ================================
# Disk and Temp Directory Settings
# ================================
# Use D: and E: drives for all temporary files
# Cleanup settings
spark.worker.cleanup.enabled           true
spark.worker.cleanup.interval          1800
spark.cleaner.periodicGC.interval      10min
